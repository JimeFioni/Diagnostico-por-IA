{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ┗ Detecci贸n de Neumon铆a con IA en Rayos X\n",
    "Este notebook utiliza modelos de transferencia de aprendizaje (ResNet50 y EfficientNetB0) para clasificar im谩genes de rayos X de t贸rax como NORMALES o con NEUMONA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Paso 1: Importar librer铆as\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19018aa9",
   "metadata": {},
   "source": [
    "2- Carga de datos\n",
    "\n",
    "Usaremos el dataset de Kaggle Chest X-Ray Images (Pneumonia)\n",
    " URL: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a114604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Paso 2: Definir rutas del dataset\n",
    "data_dir = \"chest_xray\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "test_dir = os.path.join(data_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ч Paso 3: Generadores de datos\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=resnet_preprocess,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(preprocessing_function=resnet_preprocess)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Paso 4: Funci贸n para construir modelos con Transfer Learning\n",
    "def build_model(base_model, preprocess_fn, name):\n",
    "    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = preprocess_fn(input_tensor)\n",
    "    base = base_model(include_top=False, weights='imagenet', input_tensor=x)\n",
    "    base.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output, name=name)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Paso 5: Entrenamiento\n",
    "def train_model(model, name):\n",
    "    checkpoint_path = f\"{name}_best_model.h5\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        ModelCheckpoint(checkpoint_path, save_best_only=True)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=10,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Entrenar modelos\n",
    "resnet_model = build_model(ResNet50, resnet_preprocess, \"ResNet50\")\n",
    "efficientnet_model = build_model(EfficientNetB0, efficientnet_preprocess, \"EfficientNetB0\")\n",
    "\n",
    "resnet_model, resnet_history = train_model(resnet_model, \"resnet\")\n",
    "efficientnet_model, efficientnet_history = train_model(efficientnet_model, \"efficientnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Paso 6: Evaluar modelos\n",
    "def evaluate_model(model, name):\n",
    "    print(f\"Evaluando {name}\")\n",
    "    preds = model.predict(test_generator)\n",
    "    y_pred = (preds > 0.5).astype(int)\n",
    "    y_true = test_generator.classes\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"NORMAL\", \"PNEUMONIA\"]))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"NORMAL\", \"PNEUMONIA\"],\n",
    "                yticklabels=[\"NORMAL\", \"PNEUMONIA\"])\n",
    "    plt.title(f'Matriz de Confusi贸n: {name}')\n",
    "    plt.xlabel('Predicci贸n')\n",
    "    plt.ylabel('Verdadero')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(resnet_model, \"ResNet50\")\n",
    "evaluate_model(efficientnet_model, \"EfficientNetB0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Paso 7: Visualizaci贸n Grad-CAM\n",
    "def get_img_array(img_path):\n",
    "    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    array = image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
    "    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, 0]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def display_gradcam(img_path, model, layer_name=\"conv5_block3_out\"):\n",
    "    img_array = get_img_array(img_path)\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, layer_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    heatmap = cv2.resize(heatmap, (IMG_SIZE, IMG_SIZE))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted(img, 0.6, heatmap_color, 0.4, 0)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Grad-CAM\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar activaci贸n Grad-CAM para una imagen del test set\n",
    "test_img_path = test_generator.filepaths[0]\n",
    "display_gradcam(test_img_path, resnet_model, \"conv5_block3_out\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
