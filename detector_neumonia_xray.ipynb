{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🩻 Detección de Neumonía con IA en Rayos X\n",
    "Este notebook utiliza modelos de transferencia de aprendizaje (ResNet50 y EfficientNetB0) para clasificar imágenes de rayos X de tórax como NORMALES o con NEUMONÍA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Paso 1: Importar librerías\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19018aa9",
   "metadata": {},
   "source": [
    "2- Carga de datos\n",
    "\n",
    "Usaremos el dataset de Kaggle “Chest X-Ray Images (Pneumonia)”\n",
    "📌 URL: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a114604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🗂 Paso 2: Definir rutas del dataset\n",
    "data_dir = \"chest_xray\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "test_dir = os.path.join(data_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧹 Paso 3: Generadores de datos\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=resnet_preprocess,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(preprocessing_function=resnet_preprocess)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 Paso 4: Función para construir modelos con Transfer Learning\n",
    "def build_model(base_model, preprocess_fn, name):\n",
    "    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = preprocess_fn(input_tensor)\n",
    "    base = base_model(include_top=False, weights='imagenet', input_tensor=x)\n",
    "    base.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output, name=name)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔁 Paso 5: Entrenamiento\n",
    "def train_model(model, name):\n",
    "    checkpoint_path = f\"{name}_best_model.h5\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        ModelCheckpoint(checkpoint_path, save_best_only=True)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=10,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Entrenar modelos\n",
    "resnet_model = build_model(ResNet50, resnet_preprocess, \"ResNet50\")\n",
    "efficientnet_model = build_model(EfficientNetB0, efficientnet_preprocess, \"EfficientNetB0\")\n",
    "\n",
    "resnet_model, resnet_history = train_model(resnet_model, \"resnet\")\n",
    "efficientnet_model, efficientnet_history = train_model(efficientnet_model, \"efficientnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 Paso 6: Evaluar modelos\n",
    "def evaluate_model(model, name):\n",
    "    print(f\"Evaluando {name}\")\n",
    "    preds = model.predict(test_generator)\n",
    "    y_pred = (preds > 0.5).astype(int)\n",
    "    y_true = test_generator.classes\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"NORMAL\", \"PNEUMONIA\"]))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"NORMAL\", \"PNEUMONIA\"],\n",
    "                yticklabels=[\"NORMAL\", \"PNEUMONIA\"])\n",
    "    plt.title(f'Matriz de Confusión: {name}')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Verdadero')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(resnet_model, \"ResNet50\")\n",
    "evaluate_model(efficientnet_model, \"EfficientNetB0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Paso 7: Visualización Grad-CAM\n",
    "def get_img_array(img_path):\n",
    "    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    array = image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
    "    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, 0]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def display_gradcam(img_path, model, layer_name=\"conv5_block3_out\"):\n",
    "    img_array = get_img_array(img_path)\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, layer_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    heatmap = cv2.resize(heatmap, (IMG_SIZE, IMG_SIZE))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted(img, 0.6, heatmap_color, 0.4, 0)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Grad-CAM\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar activación Grad-CAM para una imagen del test set\n",
    "test_img_path = test_generator.filepaths[0]\n",
    "display_gradcam(test_img_path, resnet_model, \"conv5_block3_out\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
