{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# \ud83e\ude7b Detecci\u00f3n de Neumon\u00eda con IA en Rayos X\nEste notebook utiliza modelos de transferencia de aprendizaje (ResNet50 y EfficientNetB0) para clasificar im\u00e1genes de rayos X de t\u00f3rax como NORMALES o con NEUMON\u00cdA."}, {"cell_type": "code", "metadata": {}, "source": "# \ud83d\udce6 Paso 1: Importar librer\u00edas\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50, EfficientNetB0\nfrom tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport cv2\nfrom tensorflow.keras.preprocessing import image\nimport warnings\nwarnings.filterwarnings(\"ignore\")"}, {"cell_type": "code", "metadata": {}, "source": "# \ud83d\uddc2 Paso 2: Definir rutas del dataset\ndata_dir = \"chest_xray\"\ntrain_dir = os.path.join(data_dir, \"train\")\nval_dir = os.path.join(data_dir, \"val\")\ntest_dir = os.path.join(data_dir, \"test\")"}, {"cell_type": "code", "metadata": {}, "source": "# \ud83e\uddf9 Paso 3: Generadores de datos\nIMG_SIZE = 224\nBATCH_SIZE = 32\n\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=resnet_preprocess,\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n)\n\nval_test_datagen = ImageDataGenerator(preprocessing_function=resnet_preprocess)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode=\"binary\",\n)\n\nval_generator = val_test_datagen.flow_from_directory(\n    val_dir,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode=\"binary\",\n    shuffle=False,\n)\n\ntest_generator = val_test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode=\"binary\",\n    shuffle=False,\n)"}, {"cell_type": "code", "metadata": {}, "source": "# \ud83e\udde0 Paso 4: Funci\u00f3n para construir modelos con Transfer Learning\ndef build_model(base_model, preprocess_fn, name):\n    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    x = preprocess_fn(input_tensor)\n    base = base_model(include_top=False, weights='imagenet', input_tensor=x)\n    base.trainable = False\n    x = GlobalAveragePooling2D()(base.output)\n    x = Dropout(0.5)(x)\n    output = Dense(1, activation='sigmoid')(x)\n\n    model = Model(inputs=input_tensor, outputs=output, name=name)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    return model"}, {"cell_type": "code", "metadata": {}, "source": "# \ud83d\udd01 Paso 5: Entrenamiento\ndef train_model(model, name):\n    checkpoint_path = f\"{name}_best_model.h5\"\n    callbacks = [\n        EarlyStopping(patience=3, restore_best_weights=True),\n        ModelCheckpoint(checkpoint_path, save_best_only=True)\n    ]\n    history = model.fit(\n        train_generator,\n        validation_data=val_generator,\n        epochs=10,\n        callbacks=callbacks\n    )\n    return model, history"}, {"cell_type": "code", "metadata": {}, "source": "# \ud83d\ude80 Entrenar modelos\nresnet_model = build_model(ResNet50, resnet_preprocess, \"ResNet50\")\nefficientnet_model = build_model(EfficientNetB0, efficientnet_preprocess, \"EfficientNetB0\")\n\nresnet_model, resnet_history = train_model(resnet_model, \"resnet\")\nefficientnet_model, efficientnet_history = train_model(efficientnet_model, \"efficientnet\")"}, {"cell_type": "code", "metadata": {}, "source": "# \ud83d\udcc8 Paso 6: Evaluar modelos\ndef evaluate_model(model, name):\n    print(f\"Evaluando {name}\")\n    preds = model.predict(test_generator)\n    y_pred = (preds > 0.5).astype(int)\n    y_true = test_generator.classes\n\n    print(classification_report(y_true, y_pred, target_names=[\"NORMAL\", \"PNEUMONIA\"]))\n    cm = confusion_matrix(y_true, y_pred)\n\n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=[\"NORMAL\", \"PNEUMONIA\"],\n                yticklabels=[\"NORMAL\", \"PNEUMONIA\"])\n    plt.title(f'Matriz de Confusi\u00f3n: {name}')\n    plt.xlabel('Predicci\u00f3n')\n    plt.ylabel('Verdadero')\n    plt.show()"}, {"cell_type": "code", "metadata": {}, "source": "evaluate_model(resnet_model, \"ResNet50\")\nevaluate_model(efficientnet_model, \"EfficientNetB0\")"}, {"cell_type": "code", "metadata": {}, "source": "# \ud83d\udd0d Paso 7: Visualizaci\u00f3n Grad-CAM\ndef get_img_array(img_path):\n    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n    array = image.img_to_array(img)\n    array = np.expand_dims(array, axis=0)\n    return array\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        loss = predictions[:, 0]\n    grads = tape.gradient(loss, conv_outputs)[0]\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n    conv_outputs = conv_outputs[0]\n    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef display_gradcam(img_path, model, layer_name=\"conv5_block3_out\"):\n    img_array = get_img_array(img_path)\n    heatmap = make_gradcam_heatmap(img_array, model, layer_name)\n    img = cv2.imread(img_path)\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    heatmap = cv2.resize(heatmap, (IMG_SIZE, IMG_SIZE))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    superimposed_img = cv2.addWeighted(img, 0.6, heatmap_color, 0.4, 0)\n\n    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n    plt.title(\"Grad-CAM\")\n    plt.axis('off')\n    plt.show()"}, {"cell_type": "code", "metadata": {}, "source": "# Mostrar activaci\u00f3n Grad-CAM para una imagen del test set\ntest_img_path = test_generator.filepaths[0]\ndisplay_gradcam(test_img_path, resnet_model, \"conv5_block3_out\")"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}